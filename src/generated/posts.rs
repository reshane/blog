use yew::prelude::*;
use std::collections::HashMap;
pub struct Posts { pub posts: HashMap::<String, Html> }
impl Posts {
    pub fn new() -> Self {
        let mut post_map = HashMap::<String, Html>::new();
    	post_map.insert(String::from("20241227_aoc_24"), html! {# Advent of Code 2024
A colleciton of some highs, lows, and buffalos from my advent of code 2024. There will be spoilers. [See here](https://github.com/reshane/aoc2024/tree/main) for my solutions.
## Background
I first came across advent of code while watching Alexey Kutepov's youtube videos, specifically [this series](https://www.youtube.com/playlist?list=PLpM-Dvs8t0VZNUvTX1pqfpI_tMkhWCLYL) where he solves all the problems while exploring templeOS and holy c (all hail king terry).
I would highly recommend watching along with his series from the previous year, where each day is completed using a different language.
I decided that this year I would be trying to complete all problems in rust, using only the standard library.
This is mostly because I had been writing a lot of rust in my free time up to this point, but also because I wanted to see if I could learn the standard library well enough to not depend on any crates.
## Highs
The first of my favorite moments from this year came on the very first day.
This is only a high because it was my first time discovering the ranking system and subsequently how slow I was, but nonetheless it was a high.
For the first day, I solved part 1 in 12 minutes and 5 seconds, and part 2 I completed at the 22 minute 5 second mark.
[my solution](https://github.com/reshane/aoc2024/blob/main/src/day1.rs) is 69 lines of code (nice), and took me so long to write not because I wasnt trying hard, but because December 1st 2024 was the end of a saturday night out for me.
The next high came on day 3 with the mul problem.
I solved part 2 by splitting the input on every `don't()`, and then for every resulting chunk except the first, apply my solution from part 1 to everything after the first `do()` of that chunk.
The first chunk being different because state starts off with the `mul`'s being enabled.
This just tickled something in my brain and felt very satisfying, and therefore it is a highlight.
Day 7 was another highlight, but only because I got to use one of my favorite tricks for part 1.
The trick is that to generate all possible sequences of two options for a given length, you can count from 0 to 2 to the power of the given length minus 1, and then use the binary representation at each increment to define a sequence.
For example, a sequence of Add and Mul of length 2 can be generated by counting from 0 to 3 in binary:
00 -> Add, Add
01 -> Add, Mul
10 -> Mul, Add
11 -> Mul, Mul
This is just a very satisfying relationship which holds true for any base, but it is easiest to define a mapping from index to sequence for base 2.
Day 15 was a highlight as well, for the same reason as day 3, but this one was much more satisfying.
Day 15 part 1 simply asks for the state of a warehouse after a robot has completed all of the instructions given as a list of directions (^v<>).
The robot can push boxes around, but not if there is a wall blocking any of the boxes the robot wants to move.
I implemented this as a state machine. In the step method of the Warehouse, I have this:
```
fn step(&mut self) {
    let dir = self.moves.remove(0);
    let dir_vec = match dir {
        Dir::Up => (0_i64, -1_i64),
        Dir::Down => (0_i64, 1_i64),
        Dir::Left => (-1_i64, 0_i64),
        Dir::Right => (1_i64, 0_i64),
    };

    let mut target = (self.robot.0 + dir_vec.0, self.robot.1 + dir_vec.1);
    let robot_next_pos = target.clone();
    let mut boxes_to_move = Vec::<Pos>::new();

    // update target until it is not in the boxes
    while self.boxes.contains(&target) {
        boxes_to_move.push(target);
        target.1 += dir_vec.1;
        target.0 += dir_vec.0;
    }

    if self.walls.contains(&target) {
        // there is a wall & we don't move
        return;
    }

    // the vector of boxes are a vertical line of boxes
    // we can just move the first encountered
    // to the empty position after last (aka target)
    if boxes_to_move.len() > 0 {
        self.boxes.remove(&robot_next_pos);
        self.boxes.insert(target);
    }
    self.robot = robot_next_pos;
}
```
And thats it.
First, the fact that the implementation works for every direction and only matches on the instruction once is very nice.
Second, and most satisfying, I only update the position of the first box, and the position of the robot.
This saves having to iterate over all of the boxes a second time after figuring out that they can actually be updated.
Unfortunately, this does not work for part 2, but this is still far and away the most satisfying bit of code that I wrote over the course of the month.
Day 17 is also worth mentioning because it was very cool to play around with the input and realize that there was a relationship between every 3 bits of the a register and each output.
I realized this a lot earlier than I was actually able to use it, but that is because I spent a lot of time trying to make powers of 8 work, rather than just shifting by 3.
Day 23 was fun because it is not often I get to use algorithms I learned in college, and I like doing it. Shoutout to Bron-Kerbosch and whoever has contributed to that wikipedia page.
## Lows
My lower moments are pretty obvious given my personal times:
![0_my_times.png](/assets/20241227_aoc_24/images/0_my_times.png)
Day 14 was tough because it took me a long time to realize that having every robot in a unique position would give the correct configuration, in fact I didn't realize this and it was a hint that I got from reddit.
In the end I was able to solve about 9 minutes after midnight which was disapointing.
Day 16 was a similar story. I was able to solve part 2 a little bit after midnight, but in this case it was because I started too late and it took me a long time to remember how to find all of the nodes I needed to.
Day 21 was unfortunate & was missed because I was extremely sick that day so I couldn't make it out of bed and over to the computer :(
Day 24 was really really tough. I was convinced until midnight of the 24th that I was going to be able to use a bfs / dfs approach where I swapped two and if that works, add that configuration to a queue or a stack or whatever.
I am still not 100% sure why that didn't work, but I know that I learned a lesson: I should not keep trying to algorithmically solve an analytical problem until it is too late.
I ended up doing it semi by hand just before the 25th day came out.
## Buffalos
When Day 25 opened up, I was almost done doing day 24 by hand, but I really wanted to try and get a good rank on the last day.
So I stashed everything for day 24 and started on day 25.
Then tragedy struck when I was able to solve day 25 part one pretty quickly, and then learned that I needed all the previous stars to finish the calendar.
I popped the stash, found made sure I had the pairs right, sorted them, printed, and submitted and was able to get the star.
Then I frantically clicked my way back over to day 25 and then delivered the chronical. That was crazy.
And I ended up getting my best scores so far on either part which was a great end to the calendar.
Day 5 was an interesting problem, I knew what a topological sort was, but had never actually written one.
I tried to sort everything by pushing each things children onto a stack, etc:
```
fn reorder(ord: &Vec<i64>, deps: &HashMap<i64, Vec<i64>>) -> Vec<i64> {
    // this sort implementation doesn't work for the problem :(
    // but does produce a vector sorted according to the topology
    let mut stack: Vec<i64> = vec![];
    for o in ord {
        // if ord contains a dependent of o
        // push the dependent onto the stack
        // if the stack already contains dep(o), dont push
        // then push o
        if let Some(o_dep) = deps.get(o) {
            let mut idx = o_dep.len();
            loop {
                idx -= 1;
                let d = o_dep[idx];
                if !stack.contains(&d) && ord.contains(&d) {
                    stack.push(d);
                }
                if idx == 0 {
                    break;
                }
            }
        }
        if !stack.contains(o) {
            stack.push(*o);
        }
    }
    stack
}
```
So I was pretty proud of this topo sort implementation, but because it didn't work for the problem, its in the buffalos :/
Overall, I had a lot of fun and the problems were great this year - despite the fact that I had to get hints on several occasions and was not able to solve every problem within 24 hours of it coming out.
I was able to solve every problem by the end of day 25, and was able to solve every problem with just the rust standard library.
Next year I'm thinking about trying to solve every day in Ocaml, but after a little bit of trying it out after solving day 25, I don't know that Ocaml will be the pick

});	post_map.insert(String::from("20241106_image_resizing"), html! {});	post_map.insert(String::from("20241125_fourier_transforms"), html! {# Fourier Transforms

As I am someone who enjoys interesting algorithms, math, and re-implementing existing things, it was only a matter of time before I wrote a fourier transform.
The first time I had the idea to do so was in college when I saw [this 3b1b video]() so thats where we'll start
This time around I wanted to implement the algorithm within an stb-style header only library, so we'll start with some data structures to support our algorithm there...
```
#ifndef FFT_H_
#define FFT_H_

// == INCLUDES ==

#include <stdio.h>
#include <math.h>
#include <complex.h>

#ifndef FFT_NO_UNI_STD
#include <unistd.h>
#endif // FFT_NO_UNI_STD

#ifndef FFT_MALLOC
#include <stdlib.h>
#define FFT_ALLOC malloc
#define FFT_FREE free
#endif // FFT_MALLOC

#ifndef FFT_ASSERT
#include <assert.h>
#define FFT_ASSERT assert
#endif // FFT_ASSERT


// == DEFINITIONS ==

// [[ CONSTANTS ]]

#define FFT_EPSILON 0.00001f

// [[ STRUCTURES ]]

// -- Vector --

typedef struct {
    size_t size;
    float complex* data;
} fft_Vec_cf;
fft_Vec_cf fft_vec_alloc(size_t cap);
void fft_vec_free(fft_Vec_cf* v);
// deprecated
float complex* fft_vec_at(fft_Vec_cf* v, size_t i);
float complex fft_vec_get(fft_Vec_cf* v, size_t i);
void fft_vec_set(fft_Vec_cf* v, size_t i, float complex e);

// -- Matrix --
typedef struct {
    size_t rows;
    size_t cols;
    float complex* data;
} fft_Matrix_cf;
fft_Matrix_cf fft_mat_alloc(size_t rows, size_t cols);
void fft_mat_free(fft_Matrix_cf* mat);
float complex fft_mat_get(fft_Matrix_cf* mat, size_t x, size_t y);
void fft_mat_set(fft_Matrix_cf* mat, size_t x, size_t y, float complex e);
```
Along with all of our includes (some made optional by putting their functions behind macros which I thought was a cool way to provide configuration to users of the library),
We define vector and matrix data structures along with some associated functions
Also defined in our `[[ CONSTANTS ]]` section is an epsilon value, which will come in handy later for floating-point stuff...
Now we can move on to the implementation of the boilerplate for our data structures
```
#ifdef FFT_IMPLEMENTATION

// == IMPLEMENTATION ==

// [[ STRUCTURES ]]

// -- Vector --

fft_Vec_cf fft_vec_alloc(size_t cap)
{
    fft_Vec_cf v;

    v.size = cap;
    v.data = FFT_ALLOC(v.size*sizeof(*v.data));
    FFT_ASSERT(v.data);

    return v;
}

void fft_vec_free(fft_Vec_cf* v)
{
    FFT_FREE(v->data);
}

float complex* fft_vec_at(fft_Vec_cf* v, size_t i)
{
    FFT_ASSERT(i < v->size);
    return &v->data[i];
}

float complex fft_vec_get(fft_Vec_cf* v, size_t i)
{
    return *fft_vec_at(v, i);
}

void fft_vec_set(fft_Vec_cf* v, size_t i, float complex e)
{
    FFT_ASSERT(i < v->size);
    *fft_vec_at(v, i) = e;
}

// -- Matrix --

fft_Matrix_cf fft_mat_alloc(size_t rows, size_t cols)
{
    fft_Matrix_cf mat;
    mat.rows = rows;
    mat.cols = cols;
    mat.data = (float complex*)malloc(sizeof(float complex)*rows*cols);
    FFT_ASSERT(mat.data);
    return mat;
}

void fft_mat_free(fft_Matrix_cf* mat)
{
    free(mat->data);
}

float complex fft_mat_get(fft_Matrix_cf* mat, size_t x, size_t y)
{
    size_t idx = y*mat->cols + x;
    FFT_ASSERT(idx<(mat->cols)*(mat->rows));
    return mat->data[idx];
}

void fft_mat_set(fft_Matrix_cf* mat, size_t x, size_t y, float complex e)
{
    size_t idx = y*mat->cols + x;
    FFT_ASSERT(idx<(mat->cols)*(mat->rows));
    mat->data[idx] = e;
}
```
Great! now we have data structures we can use to create some memory leaks
or not that - let's implement a discrete fourier tranform using our vector to get a grip on what we're actually doing
```
// [[ ALGORITHMS ]]

void dft(fft_Vec_cf* series, fft_Vec_cf* dft_series);
void dft_inverse(fft_Vec_cf* dft_series, fft_Vec_cf* series);
...

// -- Discrete Fourier Transform -- 

void dft(fft_Vec_cf* series, fft_Vec_cf* dft_series)
{
    for (size_t i=0; i<dft_series->size; ++i) {
        float complex res = 0.f;
        for (size_t j=0; j<series->size; ++j) {
            float complex xn = fft_vec_get(series, j);
            res += xn * cexp((-2.f*I*M_PI*(float)j*(float)i)/(float)dft_series->size);
        }
        fft_vec_set(dft_series, i, res);
    }
}

void dft_inverse(fft_Vec_cf* dft_series, fft_Vec_cf* series)
{
    for (size_t i=0; i<series->size; ++i) {
        float complex res = 0.f;
        for (size_t j=0; j<dft_series->size; ++j) {
            float complex xn = fft_vec_get(dft_series, j);
            res += xn * cexp((2.f*I*M_PI*(float)j*(float)i)/(float)series->size);
        }
        res /= series->size;
        fft_vec_set(series, i, res);
    }
}
```
Cool - now we have a pretty good idea what we're doing
Basically calculating the center of mass of our function when wrapped around the origin for a given frequency, which maps to the index in our resulting vector
And for computing the inverse, we go the opposite way by using omega^-1 - aka the root of unity that we are evaluating at to the -1 power.
Now we can write some tests to make sure we did everything right
```
TEST(test_dft)
{
    size_t n = 8;
    fft_Vec_cf a = fft_vec_alloc(n);
    fft_Vec_cf b = fft_vec_alloc(n);
    fft_Vec_cf c = fft_vec_alloc(n);

    fft_vec_set(&a, 0,  1.f +  0.f * I);
    fft_vec_set(&a, 1,  2.f + -1.f * I);
    fft_vec_set(&a, 2,  0.f + -1.f * I);
    fft_vec_set(&a, 3, -1.f +  2.f * I);
    fft_vec_set(&a, 4,  1.f +  0.f * I);
    fft_vec_set(&a, 5,  2.f + -1.f * I);
    fft_vec_set(&a, 6,  0.f + -1.f * I);
    fft_vec_set(&a, 7, -1.f +  2.f * I);


    fft_vec_set(&c, 0,  4.f +  0.f * I);
    fft_vec_set(&c, 1,  0.f +  0.f * I);
    fft_vec_set(&c, 2, -4.f + -4.f * I);
    fft_vec_set(&c, 3,  0.f +  0.f * I);
    fft_vec_set(&c, 4,  0.f + -4.f * I);
    fft_vec_set(&c, 5,  0.f +  0.f * I);
    fft_vec_set(&c, 6,  8.f +  8.f * I);
    fft_vec_set(&c, 7,  0.f +  0.f * I);

    dft(&a, &b);
    fft_vec_free(&a);

    for (size_t k = 0; k < n; ++k) {
        ASSERT_CF_EQ(fft_vec_get(&b, k), fft_vec_get(&c, k))
    }

    fft_vec_free(&b);
    fft_vec_free(&c);
}

TEST(test_dft_inverse)
{
    size_t n = 8;
    fft_Vec_cf a = fft_vec_alloc(n);
    fft_Vec_cf b = fft_vec_alloc(n);
    fft_Vec_cf c = fft_vec_alloc(n);

    fft_vec_set(&a, 0,  1.f +  0.f * I);
    fft_vec_set(&a, 1,  2.f + -1.f * I);
    fft_vec_set(&a, 2,  0.f + -1.f * I);
    fft_vec_set(&a, 3, -1.f +  2.f * I);
    fft_vec_set(&a, 4,  1.f +  0.f * I);
    fft_vec_set(&a, 5,  2.f + -1.f * I);
    fft_vec_set(&a, 6,  0.f + -1.f * I);
    fft_vec_set(&a, 7, -1.f +  2.f * I);


    fft_vec_set(&c, 0,  4.f +  0.f * I);
    fft_vec_set(&c, 1,  0.f +  0.f * I);
    fft_vec_set(&c, 2, -4.f + -4.f * I);
    fft_vec_set(&c, 3,  0.f +  0.f * I);
    fft_vec_set(&c, 4,  0.f + -4.f * I);
    fft_vec_set(&c, 5,  0.f +  0.f * I);
    fft_vec_set(&c, 6,  8.f +  8.f * I);
    fft_vec_set(&c, 7,  0.f +  0.f * I);

    dft_inverse(&c, &b);
    fft_vec_free(&c);

    for (size_t k = 0; k < n; ++k) {
        ASSERT_CF_EQ(fft_vec_get(&a, k), fft_vec_get(&b, k))
    }
    fft_vec_free(&a);
    fft_vec_free(&b);
}
```
Awesome - lets see if that works...
![0_dft_test_results.png](/assets/20241125_fourier_transforms/images/0_dft_test_results.png)
Now lets implement the the Fast Fourier Transform and see how much faster it is compared to the naive discrete approach..
Looking at [this wikipedia page](https://en.wikipedia.org/wiki/Butterfly_diagram) really clears up what I found to be the complicated part of implementing the algorithm
Essentially what it is doing to recombine the recursively solved sub-problems is two expressions on each pair, which generate elements at their respective indices:
```
y0 = x0 + x1*w
y1 = x0 - x1*w
```
where `x0` and `x1` are elements of the same index in the transformed sub problems, in this case `x0` comes from the even index sub-problem.
`w` in the above is our omega value, which is essentially just a root of unity - there is a lot more that goes into why these [twiddle factors]() do what they do, but the jist is that evaluating polynomials at inputs selected such that they cancel eachother out drastically reduces the number of operations that must be performed, and these specific complex numbers allow us to do that :-)
With all that knowledge, we are ready to implement our recursive-cooley-tukey fast fourier transform...
```
double complex fft_omega(size_t n, size_t k)
{
    return cexp((-2.f*I*M_PI*k)/n);
}

void fft(fft_Vec_cf* series, fft_Vec_cf* dft_series)
{
    FFT_ASSERT(series->size == dft_series->size);
    if (series->size == 1) {
        fft_vec_set(dft_series, 0, fft_vec_get(series, 0));
        return;
    }
    size_t series_count = series->size;
    FFT_ASSERT(series_count % 2 == 0);

    // split the series into even and off
    fft_Vec_cf evn = fft_vec_alloc(series_count/2);
    fft_Vec_cf odd = fft_vec_alloc(series_count/2);
    for (size_t k = 0; k < series_count/2; ++k) {
        fft_vec_set(&evn, k, fft_vec_get(series, k*2));
        fft_vec_set(&odd, k, fft_vec_get(series, (k*2)+1));
    }

    // get dft of each part
    fft_Vec_cf evn_dft = fft_vec_alloc(series_count/2);
    fft_Vec_cf odd_dft = fft_vec_alloc(series_count/2);

    fft(&evn, &evn_dft);
    fft(&odd, &odd_dft);

    fft_vec_free(&evn);
    fft_vec_free(&odd);

    // butterfly them together
    for (size_t k = 0; k < series_count/2; ++k) {
        double complex w = fft_omega(series_count, k);
        double complex x0 = fft_vec_get(&evn_dft, k);
        double complex x1 = fft_vec_get(&odd_dft, k);

        double complex y0 = x0 + x1*w;
        double complex y1 = x0 - x1*w;

        fft_vec_set(dft_series, k, y0);
        fft_vec_set(dft_series, k+series_count/2, y1);
    }

    fft_vec_free(&evn_dft);
    fft_vec_free(&odd_dft);
}
```
Pro tip: In debugging and fixing my implementation I found that it was easier to start with a pseudo-recursive implementation, where the recursive calls above to `fft` are first calls to what we know to be a working `dft`.
Then we can write some more tests to see if this thing actually works: 
![1_test_fft_dft.png](/assets/20241125_fourier_transforms/images/1_test_fft_dft.png)
![2_fft_dft_test_out.png](/assets/20241125_fourier_transforms/images/2_fft_dft_test_out.png)
You might notice I am calling an fft_inverse function in the tests, this is pretty much the same exact algorithm, but but with a slight difference in the butterfly recombination:
```
double complex w = cexp((2.f*I*M_PI*(int)k)/series_count);
double complex x0 = fft_vec_get(&evn_dft, k);
double complex x1 = fft_vec_get(&odd_dft, k);

double complex y0 = 0.5f*(x0 + x1*w);
double complex y1 = 0.5f*(x0 - x1*w);
```
Now we can explore the differences in speed of our two algorithms
We can do so by splitting the test we wrote into two sections that we will turn on and off with a macro definition, and timing each one while increasing the input (shifting `n` until one runs too slow)
![3_dft_vs_fft.webm](/assets/20241125_fourier_transforms/images/3_dft_vs_fft.webm)
The difference only gets more noticeable as n grows, but on only n = 4096, a difference of over two seconds to about 500 milliseconds is significant
It is worth noting at this point that this implementation can be improved - for example by performing it in place rather than mking a recursive call at all
Additionally, the original Cooley-Tukey algorithm, which is what we've implemented, is limited by the fact that it can only work on inputs that are a power of two in size
This can also be improved by using what is called a mixed radix
Above we split into two sub problems, but we could have also chosen to split into 3, 5, 7, 11 or some other number of groups. Importantly, this choice can be made on sub problems independent of other sub problems or parent problems, meaning it is possible to dynamically split the input based on its prime factorization.
For the theoretical, general purpose uber algorithm, the keen eyed will observe that for increasingly large prime inputs, writing more radixes for the mixed radix solution is a losing battle - i.e. there will always be a larger prime input that the algorithm will not be able to handle. For this case, we have the dft - although very slow, it will solve the problem on prime inputs.
How is this dealt with in the real world though? Well, I would choose an implementation based on domain. For example, if this is going to be used for image processing, it could accept images up to certain dimensions and then implement radixes for all primes up to that number - sounds like a lot of work, but primes get more sparse the higher you go, so how many could it really be?
As an aside, we can find out...
I haven't seen too many images larger than 3000x3000 - of course there are images that need to be much much larger than this, but for the sake of argument...
we can write a program to find some primes like this...
![4_primes_finder.png](/assets/20241125_fourier_transforms/images/4_primes_finder.png)
The temptation to start i at 0 or 1 is extremely strong, but it is important to remember that neither are prime - 1 only has one factor, and 0 has infinite factors, so although they are special little guys, this isn't about them
We start at 2 and test whether our previously found primes divide evenly into our current potential prime - something we only have to do up until it is half of our test number (because past that point we are testing what would be factors that would be multiplied by factors we already tested to produce the result - thus a redundant test).
Additionally, we can break out of the loop when we find a factor, since we only need one factor besides 1 and i to prove i is not prime
And that is how we get our 27 lines of glorious prime finding action, now to run it...
![5_primes_run.webm](/assets/20241125_fourier_transforms/images/5_primes_run.webm)
And Melissa wants me to do 10_000, so here we go...
![6_stinky_request_primes_run.webm](/assets/20241125_fourier_transforms/images/6_stinky_request_primes_run.webm)
So if we want to accept images up to 10_000x10_000, we have to implement 1_229 radixes... Not a super realistic solution, so how does one generate these implementations? There must be a pattern that can be exploited, but for now I'm going to move on to a 2 dimensional implementation without writing any other radixes (to keep things simple for myself).
Looking at a bunch of different things, including [this pdf](https://www.robots.ox.ac.uk/~az/lectures/ia/lect2.pdf) and [this video](https://www.youtube.com/watch?v=v743U7gvLq0)
it seems that a fourier transform in two dimensions can be performed via transforming all the rows individually as if they were independent 1 dimensional transforms
and then repeating the process on the columns formed by the transformed rows
Before implementing this algorithm on the  Matrix data type, I'll first do a slow version where I translate the matrices to arrays of our vector type and just call our vector functions on the row and column vectors...
```
void fft_matrix(fft_Matrix_cf* mat)
{
    size_t img_rows = mat->rows;
    size_t img_cols = mat->cols;
    fft_Vec_cf rows[img_rows];
    fft_Vec_cf dft_rows[img_rows];
    fft_Vec_cf cols[img_cols];
    fft_Vec_cf dft_cols[img_cols];

    // put the matrix rows in the rows array of vectors
    for (size_t k = 0; k < img_rows; ++k) {
        rows[k] = fft_vec_alloc(img_cols);
        for (size_t j = 0; j < img_cols; ++j) {
            fft_vec_set(&rows[k], j, fft_mat_get(mat, k, j));
        }
    }

    // perform an fft on each row
    for (size_t k = 0; k < img_rows; ++k) {
        dft_rows[k] = fft_vec_alloc(img_cols);
        fft(&rows[k], &dft_rows[k]);
        fft_vec_free(&rows[k]);
    }

    for (size_t k = 0; k < mat->rows; ++k) {
        for (size_t j = 0; j < mat->cols; ++j) {
            // double complex f = fft_vec_get(&dft_rows[k], j);
            // printf("%f+%fi ", creal(f), cimag(f));
        }
        // printf("\n");
    }

    // copy the rows over to the cols array of vectors
    for (size_t j = 0; j < img_cols; j++) {
        cols[j] = fft_vec_alloc(img_rows);
        for (size_t k = 0; k < img_rows; ++k) {
            fft_vec_set(&cols[j], k, fft_vec_get(&dft_rows[k], j));
        }
    }

    // free all the dft_rows vectors
    for (size_t k = 0; k < img_rows; ++k) {
        fft_vec_free(&dft_rows[k]);
    }

    // perform an fft on each column 
    for (size_t k = 0; k < img_cols; ++k) {
        dft_cols[k] = fft_vec_alloc(img_rows);
        fft(&cols[k], &dft_cols[k]);
        fft_vec_free(&cols[k]);
    }

    // copy the cols back into the matrix
    for (size_t k = 0; k < img_cols; ++k) {
        for (size_t j = 0; j < img_rows; ++j) {
            fft_mat_set(mat, j, k, fft_vec_get(&dft_cols[k], j));
        }
        fft_vec_free(&dft_cols[k]);
    }
}
```
And of course the inverse transform I'm doing the same thing but first the columns and calling fft_inverse on everything instead
Now we can get into transforming some images!
We'll do this with the help of the PPM format and some arrays of `uint32_t`'s:
```
size_t img_rows = 512, img_cols = 512;
uint32_t* img = (uint32_t*)malloc(img_rows*img_cols*sizeof(uint32_t));

...

void save_img_as_ppm(uint32_t* img, size_t rows, size_t cols, const char *file_path)
{
    FILE* f = fopen(file_path, "wb");
    if (f == NULL) {
        fprintf(stderr, "ERROR: could not write into file %s", file_path);//: %s\n", file_path, strerror(errno));
        exit(1);
    }
    size_t img_w = cols;
    size_t img_h = rows;
    fprintf(f, "P6\n%ld %ld 255\n", img_w, img_h);
    for (size_t y=0; y<img_h; ++y) {
        for (size_t x=0; x<img_w; ++x) {
            uint32_t pixel = img[x+y*cols];
            uint8_t bytes[3] = {
                (pixel&0x0000FF)>>8*0,// R
                (pixel&0x00FF00)>>8*1,// G
                (pixel&0xFF0000)>>8*2 // B
            };
            fwrite(bytes, sizeof(bytes), 1, f);
            assert(!ferror(f));
        }
    }
    fclose(f);
}
```
Now the world is kind of our oyster in terms of generating interesting looking things, but to try and keep things understandable, I'm going to be trying to keep everythign grayscale & keeping our values from 0-256 with these functions:
```
// multiply by 255 and put the vale in each channel
uint32_t get_color(double complex f) {
    double re = creal(f);
    double im = cimag(f);
    double mag = sqrt(re*re+im*im);
    uint32_t res = 0x00000;
    uint32_t coef = 0xFF;
    res = res | (((uint32_t)(mag*coef)&0xFF)<<8*0);
    res = res | (((uint32_t)(mag*coef)&0xFF)<<8*1);
    res = res | (((uint32_t)(mag*coef)&0xFF)<<8*2);
    return res;
}

// grab the end (which should be repeated for each channel) and normalize 0-1
double complex map_color(uint32_t color) {
    uint32_t r = color & 0xFF; // 0-255
    return (double complex)r/255.f; // 0-1
}
```
Now, we can set some pixels in our image, fourier transform it, inverse fourier transform it, and hope it comes out the other end the same as the original image as a sort of sanity test...
```
int main()
{
    size_t img_rows = 512, img_cols = 512;
    uint32_t* img = (uint32_t*)malloc(img_rows*img_cols*sizeof(uint32_t));

    fill_image_white(img, img_cols, img_rows);
    draw_circle(img_cols/2, img_rows/2, 15, img, img_cols, img_rows);

    save_img_as_ppm(img, img_rows, img_cols, "original.ppm");

    fft_Matrix_cf mat = fft_mat_alloc(img_rows, img_cols);

    for (size_t x = 0; x < img_cols; ++x) {
        for (size_t y = 0; y < img_rows; ++y) {
            fft_mat_set(&mat, x, y, map_color(img[x+y*img_cols]));
        }
    }

    fft_matrix(&mat);
    for (size_t y = 0; y < img_rows; ++y) {
        for (size_t x = 0; x < img_cols; ++x) {
            double cf = fft_mat_get(&mat, x, y);
            img[x+y*img_cols] = get_color(cf);
        }
    }
    save_img_as_ppm(img, img_rows, img_cols, "fft.ppm");

    for (size_t y = 0; y < img_rows; ++y) {
        for (size_t x = 0; x < img_cols; ++x) {
            double cf = fft_mat_get(&mat, x, y);
            img[x+y*img_cols] = get_color(cf);
        }
    }

    fft_matrix_inverse(&mat);
    for (size_t x = 0; x < img_cols; ++x) {
        for (size_t y = 0; y < img_rows; ++y) {
            double cf = fft_mat_get(&mat, x, y);
            img[x+y*img_cols] = get_color(cf);
        }
    }
    save_img_as_ppm(img, img_rows, img_cols, "restored.ppm");

    fft_mat_free(&mat);
    free(img);
    return 0;
}
```
![7_original_restored.webm](/assets/20241125_fourier_transforms/images/7_original_restored.webm)
And now we can generate a gaussian blur matrix by writing these functions...
```
double gauss(double cx, double cy, double ax, double ay, double a, double x, double y) {
    return a * exp(-1.f * ((((x-cx)*(x-cx))/2.f*ax*ax) + (((y-cy)*(y-cy))/2.f*ay*ay)));
}
void fill_blr_gaussian(fft_Matrix_cf* mat) {
    for (size_t k = 0; k < mat->cols; ++k) {
        for (size_t j = 0; j < mat->rows; ++j) {
            double alpha = 0.1f;
            double y = 1.f - gauss(256.f, 256.f, alpha, alpha, 1.f, k, j);
            fft_mat_set(mat, k, j, y*255.f);
        }
    }
}
```
Then we can pair-wise multiply our fourier transformed image by this matrix and see what we get when we perform an inverse fft on the product...
To be continued...

});	post_map.insert(String::from("20241113_convolution"), html! {# Convolution
I want to do some convolution stuff in c because it seems fun.
So I start by making a project and taking some screenshots for this blog I guess.
![0_file_structure.png](/assets/20241113_convolution/images/0_file_structure.png)
![1_initial_main_c.png](/assets/20241113_convolution/images/1_initial_main_c.png)
![2_initial_convolve_h.png](/assets/20241113_convolution/images/2_initial_convolve_h.png)
![3_initial_convolve_c.png](/assets/20241113_convolution/images/3_initial_convolve_c.png)
Now to figure out how to build all of it...
[To stack overflow!](https://stackoverflow.com/questions/1705961/how-to-link-to-a-static-library-in-c)
And we end up with this:
![4_build_script_initial.png](/assets/20241113_convolution/images/4_build_script_initial.png)
Which allows us to do this: 
![5_initial_run.webm](/assets/20241113_convolution/images/5_initial_run.webm)
Great! Now let's warm up with some light convolution before starting the crazy stuff...
For that I'm going to write a data structure to help out a little
![6_int_vector.png](/assets/20241113_convolution/images/6_int_vector.png)
Admitedly, the naming of this thing is not great, but refactoring is a beautiful thing that I expect to do a lot of later.
For now, we can just start implementing this.
Most of it is pretty simple, malloc for our structure once and then malloc/realloc for our data once the capacity is exceeded...
```
// vector

Vector_i* Vector_i_new() {
    Vector_i* new = (Vector_i*) malloc(sizeof(Vector_i));
    if (!new) {
        printf("ERROR: Could initialize vector!");
        exit(1);
    }
    new->size = 0;
    new->capacity = 0;
    new->data = NULL;
    return new;
}

void Vector_i_push(Vector_i* v, int e) {
    if (v->capacity == 0) {
        v->capacity = 1;
        v->data = (int*) malloc(v->capacity * sizeof(int));
        if (!v->data) exit(1);
    }
    else if (v->size == v->capacity) {
        v->capacity *= 2;
        int* newMem = (int*) realloc(v->data, v->capacity * sizeof(int));
        if (!newMem) {
            // we have an error here... uh-oh!
            printf("ERROR: Could not increase the size of the vector");
            exit(1);
        }
        v->data = newMem;
    }
    v->data[v->size++] = e;
}

int Vector_i_get(Vector_i* v, size_t idx) {
    assert(idx < v->size);
    return v->data[idx];
}

size_t Vector_i_size(Vector_i* v) {
    return v->size;
}

size_t Vector_i_capacity(Vector_i* v) {
    return v->capacity;
}

void Vector_i_free(Vector_i* v) {
    free(v->data);
    free(v);
}
```
Also important to implement a free function so we aren't leaking a bunch of memory.
Even though what I'm going to be using this for will pretty much exclusivly be short-lived programs, just in case I ever use it for something longer, it'll be nice to have this function.
And best practices and all that stuff of course.
We can also write a test for it
[Thanks to Kay Lack for the little test framework](https://www.youtube.com/watch?v=5aZiRjgSGQU)
![8_tests_initial.png](/assets/20241113_convolution/images/8_tests_initial.png)
(ignore all that `Vector_f` stuff, that's for later and I forgot to remove it for the screenshot...)
Now for the `Vector_i_convolve` function...
I'll want to take in two vectors to perform the convolution over eachother, so we'll call them a and b
And basically what we'll be doing is something like this:
```
                           a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
                        a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
                     a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
                  a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
               a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
            a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
         a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
      a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
   a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
   b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
      b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
         b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
            b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
               b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
                  b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
                     b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
                        b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
                           b[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
```
where we can imagine flipping b around so that its lowest indices are on the right,
and its 0th index is placed under the 0th index of a
we can then multuply the elements that are 'facing eachother', and shift b to the right
Now, dealing with the pairs of operations should look something like this
```
a[0] * b[0]
a[0] * b[1] + a[1] * b[0]
a[0] * b[2] + a[1] * b[1] + a[2] * b[0]
...
a[1] * b[9] + a[2] * b[8] * a[3] * b[7] ... 
a[2] * b[9] + a[3] * b[8] * a[4] * b[7] ... 
```
And after lots of thought and effort, we can write this function:
```
Vector_i* Vector_i_convolve(Vector_i* a, Vector_i* b) {
    Vector_i* result = Vector_i_new();

    int a_size = Vector_i_size(a);
    int b_size = Vector_i_size(b);

    int a_start = 0, b_start = 0;
    for (int i=0; i<a_size+b_size; ++i) {
        int j=a_start,k=b_start,total=0;
        while (j<a_size && k>-1) {
            total += Vector_i_get(a, j) * Vector_i_get(b, k);
            j++;
            k--;
        }
        Vector_i_push(result, total);
        if (b_start == b_size-1) {
            a_start++;
        } else {
            b_start++;
        }
    }

    return result;
}
```
and then we can try it out in our main:
(Note that I have DEBUG in a `#define` statement above main to turn the printing on/off
```
int main() {
    Vector_i* base = Vector_i_new();
    Vector_i* mask = Vector_i_new();

    for (int i = 0; i < SIZE; ++i) {
        Vector_i_push(base, i);
        if (DEBUG) printf("vector contents\n\tsize: %d\n\tcap: %d\n\tlast: %d\n", base->size, base->capacity, base->data[base->size-1]);
        Vector_i_push(mask, i);
        if (DEBUG) printf("vector contents\n\tsize: %d\n\tcap: %d\n\tlast: %d\n", mask->size, mask->capacity, mask->data[mask->size-1]);
    }

    if (DEBUG) printf("vector contents\n\tsize: %d\n\tcap: %d\n\tlast: %d\n", base->size, base->capacity, base->data[base->size-1]);
    if (DEBUG) printf("vector contents\n\tsize: %d\n\tcap: %d\n\tlast: %d\n", mask->size, mask->capacity, mask->data[mask->size-1]);

    Vector_i* result = Vector_i_convolve(base, mask);

    if (1) {
        printf("[");
        for (int i = 0; i < Vector_i_size(result); ++i) {
            printf("%d", Vector_i_get(result, i));
            if (i+1 != Vector_i_size(result)) printf(",");
        }
        printf("]");
    }

    Vector_i_free(base);
    Vector_i_free(mask);
    Vector_i_free(result);

    return 0;
}
```
And with `DEBUG = 0`, when we `./build.sh && ./build/main`
![7_vector_out_initial.png](/assets/20241113_convolution/images/7_vector_out_initial.png)
Great! Thats probably right... 
Lets start in the convolve.h file by defining our interface:
```
// matrix

typedef struct {
    size_t rows;
    size_t cols;
    int* data;
} Matrix_i;

Matrix_i* Matrix_i_new(size_t rows, size_t cols);

size_t Matrix_i_rows(Matrix_i* m);

size_t Matrix_i_cols(Matrix_i* m);

void Matrix_i_set(Matrix_i* m, size_t x, size_t y, int e);

int Matrix_i_get(Matrix_i* m, size_t x, size_t y);

void Matrix_i_free(Matrix_i* m);

Matrix_i* Matrix_i_convolve(Matrix_i* a, Matrix_i* b);
```
Now we can implement our functions, pretty much the same way we did for our `Vector_i`, which I will skip for brevity
So once we have all our helper functions we can start convolving matrices.
This is going to be a lot simpler than the vector convolution because for the vector we did a biblically accurate convolution - where it is mathematically correct.
For the matrix, we are essentially going to do the dumbed-down computer science version & just take a moving weighted sum of each element.
I am also going to ignore all of the little edges and essentially treat the middle of our matrix b as the sole point of focus.
And calculate an output for each element of a with b positioned such that its center is paired with the element of a in question.
So, for example - If we were doing a biblically accurate matrix convolution, we would have to deal with cases like this:
```
 _________
|         |
|         |
|    b    |
|        _|_______
|_______|_|       |
        |         |
        |    a    |
        |         |
        |_________|
```
In the case where we are convolving b over a, above is the visual representation of the first step
where the overlap represents elements of each matrix that are 'paired up' for this iteration,
and therefore should be multiplied pair-wise and then summed to produce the output.
If we were to do this, the resulting matrix would be larger than a...
How much larger? I'm not sure but we can figure that out now (since I don't feel like writing the function right now)
So we start with the matrices positioned as above.
We perform an operation, shift, and repeat until we find a and b in the following configuration
```
         _________
        |         |
        |         |
        |    b    |
        |_________|
        |_________|
        |         |
        |    a    |
        |         |
        |_________|
```
In the case above b and a have the same width, but regardless of relative widths, we will have done `Matrix_i_cols(a)` operations and therefore have generated as many outputs.
Then, we continue until just a single element of each is overlapping, like this
```
                 _________
                |         |
                |         |
                |    b    |
         _______|_        |
        |       |_|_______|
        |         |
        |    a    |
        |         |
        |_________|
```
So we've now done an additional `Matrix_i_cols(b) - 1` operations, and thus have generated as many outputs
Which puts us at `Matrix_i_cols(a) + Matrix_i_cols(b) - 1` 
Flipping the whole thing on it's side we can see that the same holds true for the height
And so the biblically accurate output matrix has the following dimensions:
width: `Matrix_i_cols(a) + Matrix_i_cols(b) - 1`
height: `Matrix_i_rows(a) + Matrix_i_rows(b) - 1`
Anyway, now lets write the blasphemers version
For each element in a, we apply b as if its center is at the current element of a.
Applying b involves pairing each element with an element from a by its relative position.
```
Matrix_i* Matrix_i_convolve(Matrix_i* a, Matrix_i* b) {
    size_t a_w = Matrix_i_cols(a);
    size_t a_h = Matrix_i_rows(a);

    size_t b_w = Matrix_i_cols(b);
    size_t b_h = Matrix_i_rows(b);

    Matrix_i* result = Matrix_i_new(a_w, a_h);

    for (size_t y=0; y<a_h; ++y) {
        for (size_t x=0; x<a_w; ++x) {
            uint8_t bytes[4] = {0, 0, 0, 0};
            int weighted_sum = 0;
            for (size_t i=0; i<b_h; ++i) {
                for (size_t j=0; j<b_w; ++j) {
                    int c = Matrix_i_get(b,i,j);
                    int a_x = ((x+j)-(b_w/2));
                    int a_y = ((y+i)-(b_h/2));

                    if ((a_x>-1) && (a_x<a_w) && (a_y>-1) && (a_y<a_h)) {
                        weighted_sum += Matrix_i_get(a,a_x,a_y) * c;
                    }
                }
            }
            Matrix_i_set(result,y,x, weighted_sum);
        }
    }
    return result;
}
```
Here, we are calculating the index into a by adding the current index of a and b & subtracting half of the corresponding dimension of b.
Now we can see if this thing is working...
![9_matrix_convolution_initial.ong](/assets/20241113_convolution/images/9_matrix_convolution_initial.ong)
![10_matrix_output_initial.webm](/assets/20241113_convolution/images/10_matrix_output_initial.webm)
This doesn't really do anything for us though, what is the application for a discreet finite convolution of two integer matrices?
I'm sure someone smarter than me could find a use... but I'm not smarter than me yet
But what we can do is create new matrix types for unsigned 32-bit integers & floats, then convolve the floats over the ints
We can then encode image data in the `uint32_t` matrix and applying the convolution will change the image
So lets write that function:
```
// cross-type convolution
Matrix_u32* Matrix_u32_f_convolve(Matrix_u32* a, Matrix_f* b) {
    size_t a_w = Matrix_u32_cols(a);
    size_t a_h = Matrix_u32_rows(a);

    size_t b_w = Matrix_f_cols(b);
    size_t b_h = Matrix_f_rows(b);

    Matrix_u32* result = Matrix_u32_new(a_w, a_h);

    for (size_t y=0; y<a_h; ++y) {
        for (size_t x=0; x<a_w; ++x) {
            uint32_t weighted_sum = 0;
            for (size_t i=0; i<b_h; ++i) {
                for (size_t j=0; j<b_w; ++j) {
                    float c = Matrix_f_get(b,i,j);
                    int a_x = ((x+j)-(b_w/2));
                    int a_y = ((y+i)-(b_h/2));

                    uint32_t pixel = Matrix_u32_get(a,x,y);
                    if ((a_x>-1) && (a_x<a_w) && (a_y>-1) && (a_y<a_h)) {
                        pixel = Matrix_u32_get(a,a_x,a_y);
                    }
                    // apply the mask to get the correct bytes
                    // shift them over to the right, multuply by the coefficient
                    // shift them back to where the were and add to the sum
                    weighted_sum += ((uint8_t)(((pixel&0x0000FF)>>8*0) * c))<<8*0;
                    weighted_sum += ((uint8_t)(((pixel&0x00FF00)>>8*1) * c))<<8*1;
                    weighted_sum += ((uint8_t)(((pixel&0xFF0000)>>8*2) * c))<<8*2;
                }
            }
            Matrix_u32_set(result,y,x, weighted_sum);
        }
    }
    return result;
}

```
now this compiles, and we can use it in our main function...
```
int main() {
    Matrix_u32* img = Matrix_u32_new(400, 400);
    Matrix_f* msk = Matrix_f_new(4, 4);
    tv_static(img);
    flat_blur_matrix(msk);
    save_img_as_ppm(img, "original.ppm");
    Matrix_u32* blr = Matrix_u32_f_convolve(img, msk);
    save_img_as_ppm(blr, "blurred.ppm");
    return 0;
}
```
The first thing we do above is create a 400x400 matrix to represent out image.
Then, we create a 4x4 mask that will be the box which we move over our image to blur it.
Then we fill the image with either black or white pixels by passing its pointer to the `tv_static` function, which looks like this:
```
void tv_static(Matrix_u32* img) {
    size_t w = Matrix_u32_cols(img);
    size_t h = Matrix_u32_rows(img);

    for (int y=0; y<h; ++y) {
        for (int x=0; x<w; ++x) {
            uint32_t pixel = 0xFF000000;
            if ((int)((rand()/(float)RAND_MAX) + 0.5)) {
                pixel = 0xFFFFFF;
            }
            Matrix_u32_set(img,x,y,pixel);
        }
    }
}
```
Then we can fill up our msk matrix with values that sum to 1.0f with a function like this:
```
void flat_blur_matrix(Matrix_f* msk) {
    size_t msk_w = Matrix_f_cols(msk);
    size_t msk_h = Matrix_f_rows(msk);
    for (int y=0; y<msk_h; ++y) {
        for (int x=0; x<msk_w; ++x) {
            Matrix_f_set(msk,y,x,1.0/(msk_w*msk_h));
        }
    }
}
```
Then, I use this `save_image_as_ppm` to output the data into an image file with the given name, PPM being the choice of format because it's header is extremely simple:
```
P6
WIDTH HEIGHT 255
RGB_IMAGE_BYTES
```
And this is the function used to generate that file:
```
void save_img_as_ppm(Matrix_u32* img, const char *file_path) {
    FILE* f = fopen(file_path, "wb");
    if (f == NULL) {
        fprintf(stderr, "ERROR: could not write into file %s: %s\n", file_path, strerror(errno));
        exit(1);
    }
    size_t img_w = Matrix_u32_cols(img);
    size_t img_h = Matrix_u32_rows(img);
    fprintf(f, "P6\n%d %d 255\n", img_w, img_h);
    for (size_t y=0; y<img_h; ++y) {
        for (size_t x=0; x<img_w; ++x) {
            uint32_t pixel = Matrix_u32_get(img,x,y);
            uint8_t bytes[3] = {
                (pixel&0x0000FF)>>8*0,
                (pixel&0x00FF00)>>8*1,
                (pixel&0xFF0000)>>8*2
            };
            fwrite(bytes, sizeof(bytes), 1, f);
            assert(!ferror(f));
        }
    }
    fclose(f);
}
```
Then we apply our blur to the matrix, generating a new image data matrix, and call the same function on it to save it as a PPM image file.
And just like that, we have our original.ppm:
![11_original.png](/assets/20241113_convolution/images/11_original.png)
And our blurred.ppm image:
![12_blurred.png](/assets/20241113_convolution/images/12_blurred.png)


});
        Self {
            posts: post_map,
        }
    }
}